{
  "metadata": {
    "name": "demo 4 msk stock event",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analyse Data in Kafka Topic Using KDA Flink\n\n- Please check vpc endpoint for s3 and glue since MSK cluster inside VPC \n- Please check BOOTSTRAP SSL \n- Please check MSK security connection (allows unthorized for testing)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Create a Table Connecting a Kafka Topic \n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\n\nDROP TABLE IF EXISTS stock_table;\n\nCREATE TABLE stock_table (\n    ticker STRING,\n    price DOUBLE,\n    event_time  TIMESTAMP(3),\n    WATERMARK FOR event_time AS event_time - INTERVAL \u00275\u0027 SECOND\n  )\nWITH (\n    \u0027connector\u0027 \u003d \u0027kafka\u0027,\n    \u0027topic\u0027 \u003d \u0027stock-topic\u0027,\n    \u0027properties.bootstrap.servers\u0027 \u003d \u0027b-2.democluster2.vidd98.c3.kafka.ap-southeast-1.amazonaws.com:9098,b-1.democluster2.vidd98.c3.kafka.ap-southeast-1.amazonaws.com:9098,b-3.democluster2.vidd98.c3.kafka.ap-southeast-1.amazonaws.com:9098\u0027,\n    \u0027properties.group.id\u0027 \u003d \u0027KdaStudioGroup\u0027,\n    \u0027scan.startup.mode\u0027 \u003d \u0027latest-offset\u0027,\n    \u0027format\u0027 \u003d \u0027json\u0027,\n    \u0027properties.security.protocol\u0027 \u003d \u0027SASL_SSL\u0027,\n    \u0027properties.sasl.mechanism\u0027 \u003d \u0027AWS_MSK_IAM\u0027,\n    \u0027properties.sasl.jaas.config\u0027 \u003d \u0027software.amazon.msk.auth.iam.IAMLoginModule required;\u0027,\n    \u0027properties.sasl.client.callback.handler.class\u0027 \u003d \u0027software.amazon.msk.auth.iam.IAMClientCallbackHandler\u0027\n);"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Simple Query"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nSELECT * FROM stock_table"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Tumbling Window"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nSELECT\n        stock_table.ticker as ticker,\n        AVG(stock_table.price) AS avg_price,\n        TUMBLE_ROWTIME(stock_table.event_time, INTERVAL \u002710\u0027 second) as time_event\nFROM stock_table\nGROUP BY TUMBLE(stock_table.event_time, INTERVAL \u002710\u0027 second), stock_table.ticker;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Slidding Window"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nSELECT\n    stock_table.ticker as ticker,\n    AVG(stock_table.price) AS avg_price,\n    HOP_ROWTIME(stock_table.event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute) as hop_time\nFROM stock_table\nGROUP BY HOP(stock_table.event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute), stock_table.ticker;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Sink Table - Write to S3 \n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupate)\nDROP TABLE IF EXISTS stock_output_table;\nDROP TABLE IF EXISTS stock_output_table_json;"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\n\nst_env.get_config().get_configuration().set_string(\n    \"execution.checkpointing.interval\", \"1min\"\n)\n\nst_env.get_config().get_configuration().set_string(\n    \"execution.checkpointing.mode\", \"EXACTLY_ONCE\"\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nCREATE TABLE stock_output_table(\n    ticker STRING,\n    price DOUBLE,\n    event_time TIMESTAMP(3))\n    PARTITIONED BY (ticker)\nWITH (\n    \u0027connector\u0027\u003d\u0027filesystem\u0027,\n    \u0027path\u0027\u003d\u0027s3a://data-lake-stream-20072023/kafka-data/\u0027,\n    \u0027format\u0027\u003d\u0027csv\u0027,\n    \u0027sink.partition-commit.policy.kind\u0027\u003d\u0027success-file\u0027,\n    \u0027sink.partition-commit.delay\u0027 \u003d \u00271 min\u0027\n);"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nINSERT INTO stock_output_table \nSELECT \n    ticker,\n    price,\n    event_time\nFROM stock_table"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n## Sink Table - Write to S3 \n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nCREATE TABLE stock_output_table_json(\n    ticker STRING,\n    price DOUBLE,\n    event_time TIMESTAMP(3))\n    PARTITIONED BY (ticker)\nWITH (\n    \u0027connector\u0027\u003d\u0027filesystem\u0027,\n    \u0027path\u0027\u003d\u0027s3a://data-lake-stream-20072023/kafka-data-json/\u0027,\n    \u0027format\u0027\u003d\u0027json\u0027,\n    \u0027sink.rolling-policy.rollover-interval\u0027 \u003d \u002760s\u0027,\n    \u0027sink.rolling-policy.check-interval\u0027 \u003d \u002730s\u0027\n);"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nINSERT INTO stock_output_table_json \nSELECT \n    ticker,\n    price,\n    event_time\nFROM stock_table"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\n"
    }
  ]
}